{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the appropriate libraries to start with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_validate,cross_val_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use fetch_openml to fetch the MNIST dataset from OpenML.org\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = fetch_openml('mnist_784', as_frame=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We explore the generated datasets a bit, just to confirm that are NumPy arrays and their shape and the type of their context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = mnist.data, mnist.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((70000, 784), (70000,), numpy.ndarray, str)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape, type(X[0]),type(y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.15, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((59500, 784), (59500,), (10500, 784), (10500,))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59500.0, 10500.0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)*0.85, len(X)*0.15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can confirm that all the classes have the adequate number of instances. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the function tht will display the feature vector of an instance using Matplotlib’s imshow() function. It is reshaping it to a 28 × 28 array, and display it. We use cmap=\"binary\" to get a\n",
    "grayscale color map where 0 is white and 255 is black:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_digit(image_data):\n",
    " image = image_data.reshape(28, 28)\n",
    " plt.imshow(image, cmap=\"binary\")\n",
    " plt.axis(\"off\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we plot the first 8 images of the Training and Test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, axes = plt.subplots(2, 4, figsize=(10, 5))\n",
    "fig.suptitle(\"First 8 Images from the Training Set\")\n",
    "\n",
    "for i in range(8):\n",
    "    plt.subplot(2, 4, i+1)\n",
    "    plot_digit(X_train[i])\n",
    "    plt.title(y_train[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 4, figsize=(10, 5))\n",
    "fig.suptitle(\"First 8 Images from the Test Set\")\n",
    "\n",
    "for i in range(8):\n",
    "    plt.subplot(2, 4, i+1)\n",
    "    plot_digit(X_test[i])\n",
    "    plt.title(y_test[i]) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Since this is a classification problem of distinguishing between two classes: even and odd numbers, we will first create the target vectors for this classification task. To achieve this, we will turn y_train and y_test from string type to integers to allow us do the computations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_int = y_train.astype(int) \n",
    "y_test_int = y_test.astype(int)\n",
    "\n",
    "y_train_even = (y_train_int%2 == 0) # True for all even numbers, False for all other digits\n",
    "y_test_even = (y_test_int%2 == 0)\n",
    "print(type(y_train_even), y_train_even.shape, y_train_even[:10])\n",
    "print(type(y_test_even), y_test_even.shape, y_test_even[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create an Stohastic Gradient binary classifier (SGDClassifier) and train it on the whole training set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_clf = SGDClassifier(random_state=42)\n",
    "\n",
    "\n",
    "sgd_clf.fit(X_train, y_train_even)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if working\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "some_digit = X_test[3]\n",
    "check = sgd_clf.predict([some_digit])\n",
    "print(y_test[3], check)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the MinMaxScaler as a normalization technique.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_max_scaler = MinMaxScaler()\n",
    "#stdScaler = StandardScaler()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We introduce our pipeline \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgdc_pipeline = Pipeline([\n",
    "    ('min_max_scaler', MinMaxScaler()),\n",
    "    ('sgd_clf', SGDClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "# sgdc_pipeline = Pipeline([\n",
    "#     ('std_scaler', StandardScaler()),\n",
    "#     ('sgd_clf', SGDClassifier(random_state=42))\n",
    "# ])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the pipeline to fit the training data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_prepared = sgdc_pipeline.fit(X_train,y_train_even)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train_prepared\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And use the pipeline to predict on test data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_preds = sgdc_pipeline.predict(X_test)\n",
    "sgd_preds[:8]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that only the second value is predicted faulty.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We use 3-fold cross validation and evaluate your classification pipeline by calculating the next metrics: accuracy, recall, and precision. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_sgdc_accuracy = cross_val_score(sgdc_pipeline, X_train, y_train_even, cv=3, scoring='accuracy')\n",
    "print('Cross validation accuracy scores:', cv_sgdc_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_sgdc_precision = cross_val_score(sgdc_pipeline, X_train, y_train_even, cv=3, scoring='precision')\n",
    "print('Cross validation precision scores:', cv_sgdc_precision)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_sgdc_recall = cross_val_score(sgdc_pipeline, X_train, y_train_even, cv=3, scoring='recall')\n",
    "print('Cross validation recall scores:', cv_sgdc_recall)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We introduce  a dummy model that always guesses that an image belongs to the even category to compare it with our model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_clf = DummyClassifier(strategy=\"constant\", constant=True)\n",
    "dummy_clf.fit(X_train, y_train_even)\n",
    "dummy_clf_predictions = dummy_clf.predict(X_test)\n",
    "print(dummy_clf_predictions[:20])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "And we evaluate it with the same metrics as above(accuracy, precision, recall)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_clf_accuracy = cross_val_score(dummy_clf, X_train, y_train_even, cv=3, scoring='accuracy')\n",
    "print('dummy_clf cross validation accuracy scores:', dummy_clf_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_clf_precision = cross_val_score(dummy_clf, X_train, y_train_even, cv=3, scoring='precision')\n",
    "print('dummy_clf cross validation precision scores:', dummy_clf_precision)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_clf_recall = cross_val_score(dummy_clf, X_train, y_train_even, cv=3, scoring='recall')\n",
    "print('dummy_clf cross validation recall scores:', dummy_clf_recall)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe that the accuracy and recall metrics are better on our model. The recall = 1 alone doesn't say anything, and is the value we expected as it's predicting all the even numbers correctly and never predicts a FN instance.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We calculate the confusion matrix for the training set, following the same 3-fold cross validation protocol.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_cv_predictions = cross_val_predict(sgdc_pipeline, X_train, y_train_even, cv=3) #predictions on each instance\n",
    "comfusion_matrix_cv = confusion_matrix(y_train_even, y_train_cv_predictions) \n",
    "comfusion_matrix_cv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observing the confusion matrix we see that we have 27476 True Negative predictions, 2653 False Positive predictions, 3548 False Negative predictions and 25823 True Positive predictions.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The precision score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_score(y_train_even, y_train_cv_predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the recall score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_score(y_train_even, y_train_cv_predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_train_even, y_train_cv_predictions)\n",
    "f1_score(y_train_even,y_train_cv_predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We train the sgdc_pipeline with all the training data and do the predictions also.(We had already calculated them before though and it's the X_train_prepared and sgd_preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_prepared = sgdc_pipeline.fit(X_train,y_train_even)\n",
    "sgd_preds = sgdc_pipeline.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We extract the confusion matrix using these predictions and the test data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comfusion_matrix_sgd = confusion_matrix(y_test_even, sgd_preds) \n",
    "comfusion_matrix_sgd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We compute the precision, recall and accuracy scores.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_score(y_test_even, sgd_preds)\n",
    "recall_score(y_test_even, sgd_preds)\n",
    "accuracy_score(y_test_even, sgd_preds)\n",
    "f1_score(y_test_even, sgd_preds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing the results of the metrics on the training and test data accordingly, we see that precision is lower on the test set and recall is higher. Accuracy and F1 metrics are almost the same. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We compute the False Positives (FP) and False Negatives (FN) for the predictions and the test set. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "false_positives = np.where((y_test_even == 0) & (sgd_preds == 1))[0]  \n",
    "false_negatives = np.where((y_test_even == 1) & (sgd_preds == 0))[0]  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We pick a random instance for each one of them\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnm_fp_instance = np.random.choice(false_positives)\n",
    "rnm_fn_instance = np.random.choice(false_negatives)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We plot their original images in seperate figures\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "some_digit = X_test[rnm_fp_instance] #The value of the random fp instance\n",
    "plt.figure(figsize=(5, 5))\n",
    "plot_digit(some_digit)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "some_digit = X_test[rnm_fn_instance] #The value of the random fn instance\n",
    "plt.figure(figsize=(5, 5))\n",
    "plot_digit(some_digit)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
